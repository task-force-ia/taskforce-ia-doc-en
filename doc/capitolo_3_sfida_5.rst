Challenge 5: Legal context
--------------------------

When it comes to regulating the activity of the Public Administration,
one of the fundamental challenges is the balance between the interests
of the community and those of the individual. In the field of Artificial
Intelligence (AI), ensuring this balance is particularly complex. AI
solutions require huge amounts of data, often sensitive, to be
effective. For this reason, it is necessary to analyse some of the main
legal issues that may affect AI. Among these: the principle of
transparency of administrative acts, legal liability, privacy,
information security and intellectual property.

Within the scope of Public Administration activities, the principle of
transparency is cardinal and therefore must also inspire the design of
new public services based on AI solutions. For this purpose, the
criteria to be used undoubtedly include transparency of the algorithms,
the construction logic of the databases on which they operate and
defining the related responsibilities [1]_.

Already today, AI algorithms can directly influence public assessments
and decisions, as well as the administrative procedures themselves. This
poses a problem of accountability, i.e. verifying the actual legal
liability upstream of certain decisions or results, posing a series of
challenges for Public Administration:

-  find methods that are uniform and compatible with the current system
   so that the administration can justify its actions, also in the part
   processed by AI systems.

-  indicate the data sources that feed AI and through which it has made
   its assessments, and make the managers of administrative procedures
   aware of the processing methods used by AI systems.

To ensure maximum transparency, citizens must be enabled to understand
through which path the AI system has reached a certain result [2]_.

The use of sensitive data by Public Administration AI systems can
compromise citizens’ right to privacy, as well as certain fundamental
rights of the individual, in the event that the data collected is used
to forecast events of social interest, from traffic management to crime
prevention. One of the challenges is to avoid that the use of data by PA
generates pervasive social control in contrast with fundamental
citizens’ rights.

As for the possible “threat” of the right to privacy, it may be
necessary to implement certain principles and tools present in the
European General Data Protection Regulation (GDPR), such as the Data
Protection Impact Assessment and Privacy by Design. The former requires
those who use IT tools that may violate the right to privacy to make a
prior assessment of the impact of these technologies on the protection
of personal data. The latter is based on the idea that the rules on the
protection of personal data must be already incorporated in the software
design phase, ensuring that the identification data of citizens is
anonymous or covered by pseudonym, reduced to the minimum necessary and
that its use is limited to specific purposes. The challenge is clearly
to find a balance between the development of Artificial Intelligence and
respect for citizens’ right to privacy, giving them the opportunity to
express their consent to the processing of data by intelligent systems.
   
.. rubric:: Footnotes

.. [1]
   Precisely in this regard the `Digital Administration
   Code <http://cad.readthedocs.io>`__ (DAC) has ratified the right to
   digital culture, recognising the need for specific and concrete
   training actions to the benefit of users of the services, of legal
   operators and within the various institutions. The DAC has also
   established the figure of the digital ombudsman, to whom citizens can
   send reports and complaints in case of non-compliance or violations
   related to the use of digital systems (potentially also of AI
   solutions) by public administration.

.. [2]
   Case law has already established that - in the case in which
   algorithms are used for administrative activities - the right of
   access to the algorithm must always be guaranteed, in order to verify
   that it has acted correctly and in compliance with applicable laws
   (*See* Lazio Administrative Court Ruling - Rome, Sect. III-bis, no.
   3769/2017).
