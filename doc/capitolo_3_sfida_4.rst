Challenge 4: Role of data
-------------------------

Artificial Intelligence (AI) techniques and tools are benefiting today from the enormous amount of personal and environmental data that is collected daily by IT systems. The development of new technologies is inherently collected to the quality and interoperability of this data.

Among the main AI techniques that can be used to process data, for example, is that of the so-called supervised learning. In this case, the data must be “annotated” by humans who teach the machines how to interpret it. Data annotation is a time consuming activity and it can generate uneven datasets (i.e.: similar data annotated in a different way), weakening the operation of machines and propagating errors and biases [1]_.
The role of data is connected to the challenge to secure a right organizational methodology and create the best conditions in the contexts in which the data is produced in order to guarantee consistency, quality and intelligibility of datasets.

This is also true for data collected by IoT devices and sensors that are fragmented, heterogeneous and not highly interoperable, despite being connected to one another.

In this case, data scientists need to deal with data that is very different from the one connected to some of the greatest successes in the field of AI, such as image processing, autonomous driving and web search that have been made possible thanks to the availability of large and relatively structured datasets .

A second issue connected to this challenge is the management of linked open data [2]_. This data, which may regard both the institutional task (e.g. land registry or administrative data) and the operation (e.g. internal data) of a public body is made accessible and usable in open formats. This data represents a mine of information, however, it needs to be retrieved [3]_ and filtered by means of semantic technologies and shared ontologies.

This activity is envisaged by the Digital Administration Code (DAC) and falls within the scope of the Digital Team. Regarding the huge amount of data managed by the Public Administration, AI technologies allow to use it to create widespread and shared knowledge, so as to improve transparency in the public sector and to guarantee to citizens and administrators semantic access to information and interoperability of processes, as well as a better understanding of the relationship between state and citizen.

After securing the best conditions for the proper functioning of Artificial Intelligence methodologies the Public Administration will address the task to aggregate the data it needs to support process improvement. This could be achieved through the creation of an open platform for the collection, generation and management of certain types of data, directly related to Public Administration [4]_. The decentralised use of public datasets, essential for the development of active participation practices (civic activism), requires a good governance system. It is essential to ensure the quality of the data through the generalised adoption of guidelines and appropriate content standards.
To achieve these ambitious objectives, there are many issues to be addressed, including some that have been included in the e-government plans of developed countries for many years. These include:

-  truthfulness and completeness of data;

-  data distribution and access methods;

-  design and definition of shared ontologies;

-  supervision of public dataset quality;

-  estimate of the economic value attributable to the data;

-  tools that allow citizens to monitor data production;

-  management and promotion of data access [5]_;

-  regulation of data usage [6]_.

The last three items of the list introduce a further issue: ensuring equal and non-discriminatory access to data to anyone wishing to develop AI systems.
   
.. rubric:: Footnotes

.. [1]
   Ref. the “Ethical Challenge”.

.. [2]
   Ref. `<https://www.w3.org/egov/wiki/Linked_Open_Data>`__.

.. [3]
    Information Retrieval: the set of techniques used for the targeted recovery of information in electronic format.

.. [4]
    Ref. `<https://pianotriennale-ict.readthedocs.io/it/latest/doc/09_data-analytics-framework.html>`__.

.. [5]
    For example, “grand challenges” can be called. Those organised by NIST on Speech Recognition and Machine Translation, by DARPA on Autonomous Vehicles, or by ImageNet on Vision are famous.

.. [6]
   Ref. `<http://eur-lex.europa.eu/legal-content/en/TXT/?uri=CELEX%3A32016R0679>`__.
