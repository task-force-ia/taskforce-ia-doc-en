Challenge 1: Ethics
-------------------

Artificial Intelligence, as with the appearance and affirmation of every
new technology, re-proposes the contrast between the “doom-mongers and
enthusiasts” [1]_. The **doom-mongers** fear that Artificial
Intelligence will prevail over people, will decide for them, steal their
work, discriminate against them, violate their privacy, and will
secretly control them by conditioning their lives. The **enthusiasts**,
on the other hand, dream of a world where machines are capable of
autonomously performing bureaucratic processes, of being used as
powerful computational tools to process and interpret large amounts of
data in the best way, replacing men in the most burdensome and
repetitive tasks, and creating solutions able to diminish crime and
eradicate diseases.

Basically there are two perceptions of technology, which are
diametrically opposed. That of the “doom-mongers” negatively assesses
the introduction of AI in Public Administration (PA), citing a series of
critical issues that could have negative effects not only on the
efficiency and effectiveness of the measures but also on citizens’
rights. That of the “enthusiasts”, on the other hand, considers the use
of AI to be extremely positive, believes that the implementation of
these technologies can significantly improve not only the activity of
the PA but also the quality of life of citizens and that a total and
unconditional process of research and development is therefore necessary
in this area [2]_. Two extreme points of view, each with different
peculiarities, which must be critically analysed in order to resolve the
weaknesses indicated by the “doom-mongers” and modulate the strengths
sustained by the “enthusiasts”.

The examples mentioned above are not chosen by chance, they are the
result of the debate that in recent years has been going on in the
scientific community and in civil society regarding the impact of AI
systems on our lives.

The ethical challenge of the introduction of Artificial Intelligence
solutions is represented by the need to respond in a balanced manner to
the polarisation of these two visions, integrating innovation and taking
into account the effects that this has already had and will continue to
have in the development of society, respecting and safeguarding the
universally recognised core values.

Public Administration is therefore called upon to deal with numerous and
complex ethical issues. To understand its extent, it is possible to
analyse those that represent the central elements in the public debate
and in scientific analysis:

-  **data quality and neutrality**: machine learning systems need data
   which is “annotated” [3]_ by human beings (*supervised learning*) or
   at least selected and prepared (*unsupervised learning*). This also
   includes errors or bias introduced, even inadvertently, by the
   designers, replicating them in all future applications. For example,
   datasets with bias they propagate the same evaluation errors in the
   meaning of an image or a concept, as happened, for example, with
   certain algorithms used to prevent crimes, in which the data was
   compromised by a historical series that emphasised ethnic
   differences [4]_. Ore unbalanced datasets, that overestimate or
   underestimate the weight of certain variables in the reconstruction
   of the cause-effect relationship necessary to explain certain events
   and, above all, to predict them;

-  **responsibility (accountability and liability)**: the examples
   just mentioned highlight the strong impact that Artificial
   Intelligence has on the decision-making activity of public entities.
   Both when it acts as an assistant to human beings as well as as an
   autonomous entity, AI generates effects on the lives of people in
   relation to which it is necessary to be able to establish legal
   liability. Nevertheless, the ownership of the latter is not clearly
   identifiable, since it could be attributed to the producer [5]_ or to
   the owner [6]_ of the Artificial Intelligence, or even to its end
   user [7]_. Those who design AI systems can be responsible for design
   or implementation defects, but not for behaviour caused by inadequate
   instruction datasets. Can a public decision-maker be considered
   politically responsible for the decisions made on the basis of
   algorithms that process data affected by the bias mentioned above?
   What type of responsibility can there be for Public Administration?
   If a robot hurts someone, who should be held responsible and who, if
   anyone, has the obligation to compensate the victim (and with which
   assets)? Can the public decision-maker transfer his political
   responsibility to an AI system that does not respond to a clear
   principle of representation? Is it ethically sustainable that, in
   order to improve the efficiency and effectiveness of measures,
   certain important choices can be made with the influence of an AI or
   even completely delegating them to the AI? And in trusting an AI
   system, how can its consistency be controlled over time? These are
   just some of the issues that emerge in this area and highlight the
   need to establish principles for the use of AI technologies in a
   public context.

-  **transparency and openness**: the issue of the responsibility of
   public administration also has to do with the duties of the latter
   with respect to citizens, when it decides to provide them with
   services or to make decisions that concern them, using Artificial
   Intelligence solutions. The functioning of the latter must meet
   criteria of transparency and openness. Transparency becomes a
   fundamental prerequisite to avoid discrimination and solve the
   problem of information asymmetry, guaranteeing citizens the right to
   understand public decisions. It is also necessary to think about the
   policies chosen to determine the reference indices (benchmark
   policies) to avoid effects of a larger dimension: just as an
   administrator can act in a non-transparent manner, pursuing not the
   common good but private interests, a non-transparent algorithm could
   carry out the same offences even more broadly, producing not only
   injustices but also social discrimination.

-  **protection of the private sphere**: a further need, closely linked
   to the previous one, is to protect the data of the individuals. PA
   must design services based on AI able to guarantee efficiency and
   prompt response, but also protection of citizens’ sensitive data.
   This requirement, strictly connected to the legal context, has some
   ethical peculiarities concerning the use that PA can make of the data
   that has come to its knowledge in contexts different from those in
   which it was collected. Is it ethically sustainable that PA, through
   the use of data collected for other purposes, takes action based on
   the new derived information? Is it ethical to use this data to feed
   predictive systems?

To address these challenges, it may be helpful to follow some general
principles. Among these we can mention the need for an
*anthropocentric*\  [8]_ approach, according to which Artificial
Intelligence must always be put at the service of people and not vice
versa [9]_. Moreover, there are principles of procedural (non-arbitrary
procedures), formal (equal treatment for equal individuals or groups)
and substantial (effective removal of economic and social obstacles)
equity, as well as the satisfaction of certain basic universal needs,
including respect for the freedom and rights of individuals and the
community [10]_.

.. discourse::
   :topic_identifier: 1000
   
.. rubric:: Footnotes

.. [1]
   *See* Umberto Eco, *Apocalittici e integrati (doom-mongers and
   enthusiasts)*, ed. Bompiani, 1964, Bolter, J.D, Grusin, R. 1999,
   Remediation. Understanding News Media, MIT Press Cambridge, Ma. (It.
   trans. Remediation, Guerini e Associati, Milan 2002).

.. [2]
   The utopias of the “Californian ideology” (Richard Barbrook,
   *Imaginary Futures: From Thinking Machines to the Global Village,*
   2007) are currently contrasted by the radical criticism of
   technological “solutionism” (Eugenij Morozov, *To Save Everything,
   Click Here. The Folly of Technological Solutionism,* 2013).

.. [3]
   Data that is enriched with comments and metadata. For example, a
   caption can act as a description of an image.

.. [4]
   Bruno Lepri, Nuria Oliver, Emmanuel Letouz, Alex Pentland, Patrick
   Vinck, “\ *Fair, transparent and accountable algorithmic
   decision-making processes. The premise, the proposed solutions, and
   the open challenges*\ ”, Science business media, Springer, 2017.

.. [5]
   There are neural networks whose calculation algorithms are not
   completely reconstructable, not even by their programmers, generating
   what is called the “black-box effect”. See, on these topics:
   `https://arxiv.org/pdf/1706.08606.pdf <https://arxiv.org/pdf/1706.08606.pdf>`__,
   `https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/ <https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/>`__.

.. [6]
   What currently happens in the field of robotics.

.. [7]
   With a parallel, we could cite the case of construction works. The
   builder bears full responsibility for the first years after the
   inauguration of the work, but then the responsibility passes to the
   person responsible for its maintenance.

.. [8]
   *See*
   `http://www.g7italy.it/sites/default/files/documents/ANNEX2-Artificial_Intelligence_0.pdf <http://www.g7italy.it/sites/default/files/documents/ANNEX2-Artificial_Intelligence_0.pdf>`__

.. [9]
   Necessary, paraphrasing Kantian thought, that AI “treats man always
   as an end and never as one of the means”. Immanuel Kant, *Foundation
   of the Metaphysics of Morals,* 1785. For example, the famous Asimov
   robotics laws go in this direction: a robot cannot harm a human being
   nor can it allow a human being to be harmed due to its failure to
   intervene; a robot must obey the orders given by human beings,
   provided that such orders do not contravene the First Law; a robot
   must protect its existence, provided that this self-defense does not
   conflict with the First or the Second Law.

.. [10]
   Based on very similar concepts, some countries, such as Canada

   (`https://medium.com/code-for-canada/responsible-ai-in-the-government-of-canada-a-sneak-peek-973727477bdf <https://medium.com/code-for-canada/responsible-ai-in-the-government-of-canada-a-sneak-peek-973727477bdf>`__),
   have tried to establish a sort of Ten Commandments, able to guide all
   the choices of their Public Administration in the field of Artificial
   Intelligence. But there are also those who believe that the general
   principles of ethics cannot be applied to all the sectors in which
   Artificial Intelligence can operate, rather it would be better to
   organise sectoral consultations, guided by the institutions but also
   open to stakeholders, in order to understand which codes and ethical
   charters apply to the various spheres of civil life.
