Challenge 1: Ethics
-------------------

The issue of Artificial Intelligence (AI), as with the introduction of any new technology, re-proposes the contrast between the “doom-mongers and enthusiasts" [1]_.

The **doom-mongers** fear that Artificial Intelligence will prevail over people, will decide for them, steal their jobs, discriminate against them, violate their privacy, and will secretly control them by conditioning their lives.

The **enthusiasts**, on the other hand, dream of a world where machines are able to autonomously perform bureaucratic procedures, to be used as powerful computational tools to process and interpret large amounts of data in the best way, replace humans in the most burdensome and repetitive tasks, and create solutions to reduce crime and eradicate diseases.
Basically there are two completely opposite perceptions of technology. 

The **doom-mongers** think that the introduction of AI in the Public Administration (PA) will negatively affect both the efficiency and effectiveness in the public sector and citizens’ rights.

The **enthusiasts**, on the other hand, have a positive attitude towards the use of AI. They believe that the implementation of these technologies can significantly improve not only the activity of the PA but also the quality of life of citizens and that it is pivotal to support research and development in this field [2]_.

Two antithetical points of view, each with different features, which must be critically analysed in order to address the weaknesses pointed out by the “doom-mongers” and to mitigate the strengths identified by the “enthusiasts”.

The examples mentioned above have been drawn from the he debate that in recent years has been going on in the scientific community and in civil society regarding the impact of AI systems on our lives.

The ethical challenge is inherently connected to the need to achieve a point of balance between these two opposite positions taking into consideration both the necessity of introducing innovative solutions and  the effects they have on our society, respecting and safeguarding the universally recognised core values.

The use of AI solutions that rely on algorithms for data analysis is to support the decision-making process related to social, health and judicial issues (such as risk assessment) therefore it requires a thorough reflection in terms of ethics and, more broadly, of governance.

The algorithms for data analysis involve high costs that encompass the entire evolutionary cycle of their functioning: from implementation to evolutionary maintenance, to the verification of results and to the training of users who must use them responsibly. The discourse around tax incentives for encouraging the use of AI technologies in public services can be misleading: the correct development of these tools implies high costs and great attention to the ethical aspects related to their use.

The development of AI-based decision making technologies requires adequate economic and professional resources in order to resolve ethical issues when processing data and taking decisions.. Otherwise, any given decision will only help finance the private sector, with the illusion of helping people. Or, even worse, they will imply distortions or lack of responsibility, due to the assignment of decisional errors to the algorithms instead of the decision makers.

Capitalizing on the benefits of technology requires public sector investments and commitment to improve the quality and efficiency of services and to develop systems that are secure and able to truly reduce inequalities.

The public sector needs to face complex ethical issues. Hereafter the key elementsin the public debate and scientific analysis are described:

- **data quality and neutrality**: machine learning systems need data which is “annotated” [3]_ by human beings (supervised learning) or at least selected and prepared (unsupervised learning). Designers may introduce errors or bias, that will be replicated in future applications. Biased datasets propagate the same evaluation errors in the meaning of an image or a concept, as happened, for example, with certain algorithms used to prevent crimes, in which the data was compromised by a historical series that emphasised ethnic differences [4]_ , or unbalanced datasets, that overestimate or underestimate the weight of certain variables in the reconstruction of the cause-effect relationship which is necessary to explain certain events and, above all, to predict them;

- **responsibility (accountability and liability)** [5]_: the examples just mentioned highlight the strong impact that Artificial Intelligence has on the decision-making process of public entities. Whether AI acts as an assistant to human beings or as an autonomous entity, it has effects on people’s lives . This raise the issue of liability for the consequences of any damage caused by the decisions of these systems. Nevertheless, when AI systems decide without direct human control, it is very difficult to define the liability path, from the AI system to the , producer [6]_ or owner [7]_ of the Artificial Intelligence, or even to its end user [8]_. Designers can be responsible for the design or implementation defects, but not for inadequate instruction datasets. Can a public decision-maker be considered politically responsible for the decisions made on the basis of algorithms that process data affected by the bias mentioned above? What is the level of responsibility that the Public Administration bears? Who is responsible when a robot hurts someone, and who, if anyone, has the obligation to compensate the victim? Can the public decision-maker transfer his political responsibility to an AI system that does not respond to a clear principle of representation? Is it ethically sustainable to partially or entirely delegate important choices to AI systems, in order to improve the efficiency and effectiveness in the public sector ? These are just some of the issues raised by AI systems and they highlight the need to regulate the use of AI technologies in the public system.

- **transparency and openness** [9]_: the Public Administration is also responsible for the services provided to citizens through AI solutions or algorithmic decision making process. That is, means are needed to integrate criteria of transparency and openness to the technological development of AI technology. Transparency becomes a fundamental prerequisite to avoid discrimination and face the issue of information asymmetry, guaranteeing citizens the right to understand public decisions. The policy benchmarks process is also pivotal to avoid non-transparent algorithms perpetrating or even creating new forms of injustice and discrimination. The lack of transparency in algorithmic decision-making process might lead to broader injustice than the one made by humans who may be influenced by personal interests.

- **protection of the private sphere** [10]_: a further need, closely linked to the previous one, is to protect the data of the individuals. Public services based on AI must be designed to protect sensitive data. This requirement, strictly connected to the legal context, has some ethical implications concerning the use of the data in contexts different from those in which it was collected. Is it ethically sustainable that the Public Administration takes action based on information derived from data collected for other purposes? Is it ethical to use this data to feed predictive systems? To address these challenges, it may be helpful to follow some general principles. Among these we can mention the r anthropocentric [11]_ approach, stating that Artificial Intelligence is always at the service of the citizen and not vice versa [12]_. Moreover, there are the principles of procedural (non-arbitrary procedures), formal (equal treatment for equal individuals or groups) and substantial (effective removal of economic and social obstacles) equity, as well as the satisfaction of certain basic universal needs, including respect for the freedom and rights of individuals and the community [13]_. These and many other aspects related to the need to place AI at the service of people in every context are analysed in the subsequent challenges.
 
 
.. rubric:: Footnotes
.. [1]
  Ref. Umberto Eco, Apocalittici e integrati, Bompiani, 1964.
  
.. [2]
 The utopias of the “Californian ideology” (Richard Barbrook, Imaginary Futures: From Thinking Machines to the Global Village, 2007) are currently contrasted by the radical criticism of technological “solutionism” (Eugenij Morozov, To Save Everything, Click Here. The Folly of Technological Solutionism, 2013). 
 
.. [3]
  Data enriched with comments and metadata. For example, a caption can act as a description of an image.
  
.. [4]
  Bruno Lepri, Nuria Oliver, Emmanuel Letouz, Alex Pentland, Patrick Vinck, “\ *Fair, transparent and accountable algorithmic
  decision-making processes. The premise, the proposed solutions, and the open challenges*\ ”, Science business media, Springer, 2017.
  
.. [5]
  Ref. “Legal challenge”.
  
.. [6]
  There are neural networks whose calculation algorithms are not completely reconstructable, not even by their programmers, generating what is called the “black-box effect”.
  
.. [7]
  What currently happens in the field of robotics.
  
.. [8]
  With a parallel, we could cite the case of construction works. The builder bears full responsibility for the first years after the inauguration of the work, but then the responsibility passes to the person responsible for its maintenance.
  
.. [9]
 Ref. “Legal challenge”.
 
.. [10]
 Ref. “Legal challenge”.
 
.. [11]
 Ref. `<http://www.g7italy.it/sites/default/files/documents/ANNEX2-Artificial_Intelligence_0.pdf>`__.
 
.. [12]
  Necessary, paraphrasing Kantian thought, that AI “treats man always as an end and never as one of the means”. Immanuel Kant, Fondazione della metafisica dei costumi, 1785.
  
.. [13]
  Ref. `<https://medium.com/code-for-canada/responsible-ai-in-the-government-of-canada-a-sneak-peek-973727477bdf>`__.

